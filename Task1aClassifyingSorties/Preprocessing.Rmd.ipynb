{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd2bf18",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634047eb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Before You Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b7385",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Requirements\n",
    "[Jupyter](https://jupyter.org/install)\n",
    "    \n",
    "### Installing and Running\n",
    "This code may be run in an R environment in Jupyter notebooks or any terminal that runs R. \n",
    "\n",
    "### Website\n",
    "   https://maneuver-id.mit.edu/\n",
    "### About\n",
    "   The U.S. Air Force released a dataset from Pilot Training Next (PTN) through the AI Accelerator of Air Force pilots and trainees flying in virtual reality simulators. In an effort to enable AI coaching and automatic maneuver grading in pilot training, the Air Force seeks to automatically identify and label each maneuver flown in this dataset from a catalog of around 30 maneuvers. Your solution helps advance the state of the art in flying training!\n",
    "### Challenges \n",
    "This notebook addresses the second challenge: identifying maneuvers in unlabeled data based on sample maneuver data. It should be run along with the Preprocessing.Rmd notebook/file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff52ed",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8acde14",
   "metadata": {},
   "source": [
    "In order to conduct the analysis required for this portion of the lab, the following packages are required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e481a131",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:1:4: unexpected symbol\n1: {r setup\n       ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:1:4: unexpected symbol\n1: {r setup\n       ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "{r setup, include=FALSE}\n",
    "library(tidyverse)\n",
    "set.seed(2023)\n",
    "knitr::opts_chunk$set(echo = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2c99a",
   "metadata": {},
   "source": [
    "# Loading the Data Sets into R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa2976",
   "metadata": {},
   "source": [
    "The first step to play with the data is to load in the TSV files. We begin by looping through the good and bad folders obtained with our preprocessing steps. We will navigate to each directory, identify all the .tsv files and the iteratively load them into the data frame, *df*. \n",
    "\n",
    "Due to the large amount of data, the code can take some time to load. Therefore, the data frame, *df* has been saved as an .RData file. The LoadedSorties.RData file is located in the Data directory and can be loaded to prevent needing to run this page of code. The LoadedSorties.RData file also handles the removal of NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7857c637",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in read_delim(x, delim = \"\\t\"): could not find function \"read_delim\"\n",
     "output_type": "error",
     "traceback": [
      "Error in read_delim(x, delim = \"\\t\"): could not find function \"read_delim\"\nTraceback:\n",
      "1. lapply(files, load_tsv)",
      "2. FUN(X[[i]], ...)"
     ]
    }
   ],
   "source": [
    "#create original data frame to store in the TSV\n",
    "df<- data.frame()\n",
    "\n",
    "#Function to load in data\n",
    "load_tsv <- function(x){\n",
    "  \n",
    "  #load Data\n",
    "  df_temp = read_delim(x, delim = \"\\t\")\n",
    "  \n",
    "  #Determine sortie\n",
    "  df_temp = mutate(df_temp, sortieNum = strsplit(basename(x), \"[.]\")[[1]][1])\n",
    "  \n",
    "  #determine good v bad\n",
    "  if(str_detect(x, \"/good_tsv/\")){\n",
    "    lab = \"good\"\n",
    "  }else{\n",
    "    lab = \"bad\"\n",
    "  }\n",
    "\n",
    "  df_temp = mutate(df_temp, label = lab)\n",
    "  \n",
    "  #get rid of column number and rename columns\n",
    "  df_temp = df_temp[,-1]\n",
    "  colnames(df_temp) = c( \"timeSecond\", \"xEastPos\", \"yNorthPos\", \"zUpPos\", \"xEastVel\", \"yNorthVel\", \"zUpVel\", \"headingDeg\", \"pitchDeg\", \"rollDeg\",\"sortieNum\", \"label\")\n",
    "  \n",
    "  df <<- rbind(df, df_temp)\n",
    "}\n",
    "#set wd\n",
    "setwd(\"../../Pipeline/Step0_Raw/data/ObservedTrajectory/12000000000_tsv_good\") #Change to directory with good tsv files\n",
    "\n",
    "#Current Directory must be Observed Trajectory Folder\n",
    "files <- list.files(pattern=\"*.min.tsv\", full.names=TRUE, recursive=TRUE)\n",
    "lapply(files, load_tsv)\n",
    "#clean up df\n",
    "df$label <- as.factor(df$label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f2cfd",
   "metadata": {},
   "source": [
    "# Handling NA Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caed550c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "numeric(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next is to handle NA values. Check how many NA values exist.\n",
    "\n",
    "sum(is.na(df))\n",
    "colSums(is.na(df))\n",
    "\n",
    "#Although there is 78371 NA values, almost all are contributed to missing velocities. However, only 18 sorties are contributing to these 78371 values.\n",
    "na_rows <- which(is.na(df), arr.ind = TRUE)[,1]\n",
    "na_sorties <- unique(df[na_rows,]$sortieNum)\n",
    "length(na_sorties)\n",
    "\n",
    "#These 18 sorties will be removed from the data to ensure only valid data is being analyzed. \n",
    " \n",
    "df <- df[!(df$sortieNum %in% na_sorties),]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a3acab",
   "metadata": {},
   "source": [
    "\n",
    "To ensure the model is training on the contents of each sortie rather than the quantity of each observation, the training and testing set will be artificial balanced. The validation set will be unbalanced and reflect the true proportion of sorties.\n",
    "\n",
    "In addition to balancing the data set, the limited number of bad data points requires a smart choice to be made to ensure the training/testing data does not end in the validation set. To maximize the training data, 600 sorties from each group (\"good\" and \"bad\") sorties were selected and then removed from the available pool. Then 75 sorties from each group were selected for the testing set. Finally, the two groups were combined and a final 150 sorties were polled to create the validation set.\n",
    "\n",
    " Let us identify our sample of sorties used in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a12afc",
   "metadata": {},
   "source": [
    "# Creating Training, Testing, and Validation Sets\n",
    "At this point, the dataframe *df* has been saved as LoadedSorties.RDS in the Data directory. The next step is to explore the data to determine how to best create training and testing sets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "023f372e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "NaN"
      ],
      "text/latex": [
       "NaN"
      ],
      "text/markdown": [
       "NaN"
      ],
      "text/plain": [
       "[1] NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in sample.int(length(x), size, replace, prob): invalid first argument\n",
     "output_type": "error",
     "traceback": [
      "Error in sample.int(length(x), size, replace, prob): invalid first argument\nTraceback:\n",
      "1. sample(badSorties, 600)",
      "2. sample.int(length(x), size, replace, prob)"
     ]
    }
   ],
   "source": [
    "#Total Number of Sorties\n",
    "length(unique(df$sortieNum))\n",
    "#Number of \"Good\" Sorties\n",
    "goodSorties <- unique(df$sortieNum[which(df$label == 'good')])\n",
    "length(goodSorties)\n",
    "#Number of \"Bad\" Sorties\n",
    "badSorties <- unique(df$sortieNum[which(df$label == 'bad')])\n",
    "length(badSorties)\n",
    "#Proportion of total sorties that are \"Good\"\n",
    "length(goodSorties)/length(unique(df$sortieNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa476ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sorties = c(sample(badSorties, 600), sample(goodSorties,600))\n",
    "\n",
    "remainingSortiesBad <- subset(badSorties, !(badSorties %in% training_sorties))\n",
    "remainingSortiesGood <- subset(goodSorties, !(goodSorties %in% training_sorties))\n",
    "\n",
    "testing_sorties = c(sample(remainingSortiesBad, 75),sample(remainingSortiesGood, 75))\n",
    "\n",
    "remainingSortiesBad <- subset(remainingSortiesBad, !(remainingSortiesBad %in% testing_sorties))\n",
    "remainingSortiesGood <- subset(remainingSortiesGood, !(remainingSortiesGood %in% testing_sorties))\n",
    "\n",
    "validation_sorties = c(sample(c(remainingSortiesBad, remainingSortiesGood), 150))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c10e60",
   "metadata": {},
   "source": [
    "Now, the data from the main data frame will be extracted to create training, testing, and validation data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53cde838",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in sortieNum %in% training_sorties: object 'sortieNum' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in sortieNum %in% training_sorties: object 'sortieNum' not found\nTraceback:\n",
      "1. subset(df, sortieNum %in% training_sorties)",
      "2. subset.default(df, sortieNum %in% training_sorties)",
      "3. sortieNum %in% training_sorties"
     ]
    }
   ],
   "source": [
    "training_df <- subset(df, sortieNum %in% training_sorties)\n",
    "testing_df <- subset(df, sortieNum %in% testing_sorties)\n",
    "validation_df <- subset(df, sortieNum %in% validation_sorties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d48803",
   "metadata": {},
   "source": [
    "Now, a training, testing, and validation set has been achieved and can be utilized to complete task 1. To prevent having to reload data and the potential for differing sampling, these three sets have been saved in the data folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:R]",
   "language": "R",
   "name": "conda-env-R-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
