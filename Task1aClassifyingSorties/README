This document outlines the two code files involved in completing the first task- Task 1, Classifying Sorties.

# Preprocessing
This file takes the given data (good and bad png and tsv files) and iterates through them to sort out the tsv files and load them in. NA values are dealt with by identifying which sorties they are found in and getting rid of those sorties. 

To maximize the training data, 600 sorties from each group ("good" and "bad") sorties were selected and then removed from the available pool. Then 75 sorties from each group were selected for the testing set. Finally, the two groups were combined and a final 150 sorties were polled to create the validation set.

The dataframe df (compiled by sorting selecting the valid tsv files) is saved as LoadedSorties.RDS in the Data directory. The data frame is extracted to create training, testing, and validation data frames. Once this code has been run all the way through, a training, testing, and validation set has been achieved and can be utilized to complete task 1. To prevent having to reload data and the potential for differing sampling, these three sets have been saved in the data folder

# Summary Statistics

A function (augment_summary_stats) takes the preprocessed data as input to return relevant statistics such as mean, median, maximum, minimum, and quartile values. This function was run on the training set, testing set, and the validation set. The data is stored in training_ss, testing_ss and validation_ss respectively.
